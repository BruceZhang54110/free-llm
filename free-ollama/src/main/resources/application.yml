spring:
    application:
        name: free-ollama
langchain4j:
    ollama:
        chatModel:
            base-url: http://localhost:11434
            model-name: llama2
        streaming-chat-model:
            base-url: http://localhost:11434
            model-name: llama2
        language-model:
            base-url: http://localhost:11434
            model-name: llama2
logging:
    level:
        root: DEBUG
        dev:
            langchain4j: DEBUG
            ai4j:
                openai4j: DEBUG
